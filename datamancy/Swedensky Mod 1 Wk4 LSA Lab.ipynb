{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Charles Swedensky\n",
    "#CSC570 Data Science Essentials\n",
    "#Module 1 Week 4: Latent Semantic Analysis\n",
    "#26 Jan 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "categories = ['talk.politics.guns']\n",
    "dataset = fetch_20newsgroups(subset='all',shuffle=True, random_state=42, categories=categories)\n",
    "gunCorpus = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Charles\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910L,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'From: pat@rwing.UUCP (Pat Myrto)\\nSubject: Re: FBI Director\\'s Statement on Waco Standoff\\nDistribution: misc.legal,tx.general,tx.politics.talk.politics.guns,alt.law-enforcement\\nOrganization: Totally Unorganized\\nLines: 36\\n\\n\\nIn article <C5w0C9.2D0@intellection.com> emcguire@intellection.com (Ed McGuire) writes:\\n>In <1993Apr21.182458.12735@aio.jsc.nasa.gov> news&aio.jsc.nasa.gov (USENET) News (brenda kenworthy) writes:\\n>\\n>>And another thing that puzzles\\n>>me--why are they finding dead bodies inside who had bullet holes already in \\n>>them???  Don\\'t you think it\\'s possible that Koresh shot the TRAITORS rather \\n>>than letting them out???\\n>\\n>Possible.  I wouldn\\'t put it past him.  It is also possible that they\\n>were hit by rounds exploding in the extreme heat.  Remember that kept\\n>the cops away for hours.  I have only heard that bodies were found\\n>shot, not any coroner\\'s cause of death.\\n\\nSo far, the medical examiner (according to the news) has found NO EVIDENCE\\nof gunshot wounds in bodies so far examined.  If this continues to be\\nthe case, it will sort of shoot holes (pun intended) in the FBI story,\\nwouldn\\'t it?  And cartridges going off outside a firearm do not launch\\na bullet like they do when fired from a gun.  The bullet hardly moves,\\nit is the brass casing that goes flying, and then with less than lethal\\nforce.  It will hurt, yes, but not KILL you - I doubt if it wil penetrate\\na coat, for example.\\n\\nHow about an INDEPENDENT investigation, with full subpoena powers, and\\npowers to prosecute on felony charges, to investigate for any possible\\nillegal/criminal activity on the part of both the BATF and FBI?  I\\ncannot see any reason why not - to use the phrase they like to use\\nso often, \"if they have nothing to hide...\" they should welcome it,\\nand vigorously support it.  Note that an internal investigation by the\\nDept of Justice is NOT an independent investigation...\\n\\n-- \\npat@rwing.uucp      [Without prejudice UCC 1-207]     (Pat Myrto) Seattle, WA\\n         If all else fails, try:       ...!uunet!pilchuck!rwing!pat\\nWISDOM: \"Only two things are infinite; the universe and human stupidity,\\n         and I am not sure about the former.\"              - Albert Einstien\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just checking the contents to see if I've got the right corpus\n",
    "gunCorpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yep, that's about guns, alright\n",
    "#next bring in the stopwords\n",
    "stopset = set(stopwords.words('english'))\n",
    "#add URL junk to stopword set\n",
    "stopset.update(['com', 'edu', 'www', 'http', 'https', 'sw', 'uiuc', 'nntp', 'cs', 'cdt', 'wpi', 'dave', 'david', 'org', 'batf', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ngram_range -- check for important phrases up to three-words long\n",
    "vectorizer = TfidfVectorizer(stop_words=stopset, use_idf=True, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(gunCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 88877)\t0.0336220696118\n",
      "  (0, 207537)\t0.0336220696118\n",
      "  (0, 205288)\t0.0336220696118\n",
      "  (0, 107994)\t0.0336220696118\n",
      "  (0, 221868)\t0.0336220696118\n",
      "  (0, 112135)\t0.0336220696118\n",
      "  (0, 212826)\t0.0336220696118\n",
      "  (0, 219856)\t0.0336220696118\n",
      "  (0, 234022)\t0.0336220696118\n",
      "  (0, 158105)\t0.0336220696118\n",
      "  (0, 185629)\t0.0336220696118\n",
      "  (0, 161810)\t0.0336220696118\n",
      "  (0, 225134)\t0.0336220696118\n",
      "  (0, 218908)\t0.0336220696118\n",
      "  (0, 80754)\t0.0336220696118\n",
      "  (0, 73251)\t0.0336220696118\n",
      "  (0, 228124)\t0.0336220696118\n",
      "  (0, 189448)\t0.0336220696118\n",
      "  (0, 144293)\t0.0336220696118\n",
      "  (0, 158093)\t0.0336220696118\n",
      "  (0, 5665)\t0.0336220696118\n",
      "  (0, 220389)\t0.0336220696118\n",
      "  (0, 166796)\t0.0336220696118\n",
      "  (0, 234400)\t0.0336220696118\n",
      "  (0, 225112)\t0.0336220696118\n",
      "  :\t:\n",
      "  (0, 128400)\t0.00632237600005\n",
      "  (0, 222361)\t0.0322143660337\n",
      "  (0, 216814)\t0.0263503780885\n",
      "  (0, 154527)\t0.00654127187709\n",
      "  (0, 74184)\t0.0231611193264\n",
      "  (0, 123297)\t0.0160983912251\n",
      "  (0, 20424)\t0.0303995204763\n",
      "  (0, 99531)\t0.0146191839217\n",
      "  (0, 209517)\t0.0218137847366\n",
      "  (0, 164342)\t0.0487433317718\n",
      "  (0, 92104)\t0.0219776513818\n",
      "  (0, 219903)\t0.049753232397\n",
      "  (0, 125057)\t0.0235749405134\n",
      "  (0, 140726)\t0.0379947963184\n",
      "  (0, 68663)\t0.0127914243145\n",
      "  (0, 200857)\t0.0272403739965\n",
      "  (0, 228175)\t0.0148028125947\n",
      "  (0, 201921)\t0.0243716658859\n",
      "  (0, 67602)\t0.0285063073132\n",
      "  (0, 81847)\t0.0437030567569\n",
      "  (0, 205408)\t0.00630851113484\n",
      "  (0, 144291)\t0.0601834543648\n",
      "  (0, 225088)\t0.0541040924921\n",
      "  (0, 185623)\t0.0902751815471\n",
      "  (0, 158091)\t0.146246714526\n"
     ]
    }
   ],
   "source": [
    "#weighted values for the bag of words in the corpus, minus stopwords\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 241301)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#documents x terms\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=910, n_iter=100,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#truncated singular value decomposition\n",
    "#decompose matrix X\n",
    "lsa = TruncatedSVD(n_components=910, n_iter=100)\n",
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.54065116e-03,   5.02554557e-04,   5.02554557e-04, ...,\n",
       "         7.72209123e-06,   7.72209123e-06,   7.72209123e-06])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#that took awhile\n",
    "#list the calculated importance for the first concept\n",
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0:\n",
      "stratus\n",
      "gun\n",
      "would\n",
      "people\n",
      "fbi\n",
      "writes\n",
      "article\n",
      "never\n",
      "fire\n",
      "one\n",
      " \n",
      "Concept 1:\n",
      "stratus\n",
      "rocket stratus\n",
      "irvine\n",
      "rocket\n",
      "cso\n",
      "electric\n",
      "stove\n",
      "stratus tavares\n",
      "tavares\n",
      "brent\n",
      " \n",
      "Concept 2:\n",
      "handheld\n",
      "never\n",
      "roby\n",
      "jmd\n",
      "udel\n",
      "never never\n",
      "jim\n",
      "fbi\n",
      "chopin\n",
      "chopin udel\n",
      " \n",
      "Concept 3:\n",
      "irvine\n",
      "cso\n",
      "indiana\n",
      "brent\n",
      "brent irvine\n",
      "irvine uxh\n",
      "irvine uxh cso\n",
      "uxh\n",
      "uxh cso\n",
      "electric\n",
      " \n",
      "Concept 4:\n",
      "fire\n",
      "oldham\n",
      "feustel\n",
      "blast\n",
      "proper equipment\n",
      "compound\n",
      "roby\n",
      "equipment\n",
      "waco\n",
      "fbi\n",
      " \n",
      "Concept 5:\n",
      "roby\n",
      "udel\n",
      "betz\n",
      "chopin\n",
      "chopin udel\n",
      "gozer\n",
      "idbsu\n",
      "roby chopin\n",
      "roby chopin udel\n",
      "fbi\n",
      " \n",
      "Concept 6:\n",
      "feustel\n",
      "feustel netcom\n",
      "netcom\n",
      "dseg\n",
      "ti\n",
      "pyron\n",
      "government\n",
      "netcom feustel\n",
      "dseg ti\n",
      "skndiv\n",
      " \n",
      "Concept 7:\n",
      "dseg\n",
      "ti\n",
      "pyron\n",
      "dseg ti\n",
      "skndiv\n",
      "skndiv dseg\n",
      "skndiv dseg ti\n",
      "pyron skndiv\n",
      "pyron skndiv dseg\n",
      "dillon pyron\n",
      " \n",
      "Concept 8:\n",
      "indiana\n",
      "ucs\n",
      "ucs indiana\n",
      "silver ucs\n",
      "silver ucs indiana\n",
      "funny\n",
      "silver\n",
      "psych indiana\n",
      "psych\n",
      "nate\n",
      " \n",
      "Concept 9:\n",
      "kratz\n",
      "uic\n",
      "uicvm\n",
      "andy\n",
      "jason\n",
      "gang\n",
      "uicvm uic\n",
      "auto\n",
      "stanford\n",
      "semi\n",
      " \n",
      "Concept 10:\n",
      "manes\n",
      "000\n",
      "rate\n",
      "gun\n",
      "linknet\n",
      "magpie\n",
      "magpie linknet\n",
      "uk\n",
      "deaths\n",
      "handgun\n",
      " \n",
      "Concept 11:\n",
      "atf\n",
      "kent\n",
      "children\n",
      "mcs kent\n",
      "mcs\n",
      "greig\n",
      "survivors\n",
      "fbi\n",
      "fire\n",
      "dividian ranch\n",
      " \n",
      "Concept 12:\n",
      "cc utexas\n",
      "uh\n",
      "utexas\n",
      "texas\n",
      "cc\n",
      "thomasp\n",
      "ifi\n",
      "ifi uio\n",
      "uio\n",
      "mikey\n",
      " \n",
      "Concept 13:\n",
      "betz\n",
      "gozer\n",
      "trincoll\n",
      "idbsu\n",
      "betz gozer\n",
      "betz gozer idbsu\n",
      "gozer idbsu\n",
      "clinton\n",
      "banging\n",
      "baptists\n",
      " \n",
      "Concept 14:\n",
      "manes\n",
      "uk\n",
      "linknet\n",
      "magpie\n",
      "magpie linknet\n",
      "uh\n",
      "rate\n",
      "militia\n",
      "000\n",
      "switzerland\n",
      " \n",
      "Concept 15:\n",
      "children\n",
      "trincoll\n",
      "joe\n",
      "accidental\n",
      "gun buyback\n",
      "gun buyback programs\n",
      "buyback\n",
      "programs\n",
      "koresh\n",
      "buyback programs\n",
      " \n",
      "Concept 16:\n",
      "cc utexas\n",
      "utexas\n",
      "gnv\n",
      "gnv ifas\n",
      "gnv ifas ufl\n",
      "ifas\n",
      "ifas ufl\n",
      "nodak\n",
      "ufl\n",
      "green\n",
      " \n",
      "Concept 17:\n",
      "veal\n",
      "utk\n",
      "utkvm1\n",
      "utkvm1 utk\n",
      "education\n",
      "pa146008\n",
      "pa146008 utkvm1\n",
      "pa146008 utkvm1 utk\n",
      "tennessee\n",
      "roby\n",
      " \n",
      "Concept 18:\n",
      "kent\n",
      "mcs kent\n",
      "mcs\n",
      "uh\n",
      "firearms\n",
      "kent lawnmowerman\n",
      "lawnmowerman\n",
      "mhamilto\n",
      "gnv\n",
      "gnv ifas\n",
      " \n",
      "Concept 19:\n",
      "uh\n",
      "veal\n",
      "militia\n",
      "utk\n",
      "utkvm1\n",
      "utkvm1 utk\n",
      "programs\n",
      "buyback\n",
      "school\n",
      "gun buyback\n",
      " \n",
      "Concept 20:\n",
      "ifi\n",
      "ifi uio\n",
      "uio\n",
      "thomasp\n",
      "right\n",
      "three fires\n",
      "fuck\n",
      "freaks\n",
      "paranoid\n",
      "paranoid freaks\n",
      " \n",
      "Concept 21:\n",
      "fire\n",
      "firearms\n",
      "gas\n",
      "ufl\n",
      "would\n",
      "uh\n",
      "bd\n",
      "gnv\n",
      "gnv ifas\n",
      "gnv ifas ufl\n",
      " \n",
      "Concept 22:\n",
      "buy back\n",
      "iastate\n",
      "gun buy back\n",
      "gun buy\n",
      "back\n",
      "greig\n",
      "buy\n",
      "viking\n",
      "gun\n",
      "dan sorenson\n",
      " \n",
      "Concept 23:\n",
      "greig\n",
      "ac\n",
      "dct\n",
      "uk\n",
      "dct ac\n",
      "dct ac uk\n",
      "alan greig\n",
      "ac uk\n",
      "alan\n",
      "308810\n",
      " \n",
      "Concept 24:\n",
      "sun\n",
      "central sun\n",
      "central\n",
      "clesun\n",
      "clesun central\n",
      "clesun central sun\n",
      "gun\n",
      "gun buy back\n",
      "buy back\n",
      "gun buy\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#correlate the calculated weights to their actual English words\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    #just print the first 25 concepts -- 910 is too many\n",
    "    if i < 25:\n",
    "        termsInComp = zip (terms,comp)\n",
    "        sortedTerms =  sorted(termsInComp, key=lambda x: x[1], reverse=True) [:10]\n",
    "        print(\"Concept %d:\" % i )\n",
    "        for term in sortedTerms:\n",
    "            print(term[0])\n",
    "        print (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some familiar patterns emerged from the concept groups. The most impressive one to me is the \"gun buy back\" three-word phrase. Some of the other relationships the TF-IDF tied together were \"gun safety\" and \"paranoid freaks\". There are also some flashes of insight in words like \"militia\", \"Waco\", and \"government\". \n",
    "\n",
    "### I tried my best to remove as many URL-related stopwords as possible, but I think they still had some impact. Some seemingly meaningless numbers appeared in some of the concept groups as well as what seems to be the names of universities, which might be indicitive of in-work citations made by the authors of these writings.\n",
    "\n",
    "### Practical uses of this might include categorizing disorganized text data or maybe as a tool to keep a data mining algorithm \"interested\" in the right subject matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
